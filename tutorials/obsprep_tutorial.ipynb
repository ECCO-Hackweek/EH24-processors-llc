{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b7315a85-3041-459a-9d0e-f95c7d75e742",
   "metadata": {},
   "source": [
    "# Tutorial #1: Generate insitu dataset for `pkg/obsfit`\n",
    "\n",
    "In this tutorial, we demonstrate how to construct a dataset of insitu observations suitable for use with `pkg/obsfit` in the lat-lon-cap (llc) grid configuration). The main hurdle here is that the llc grid is a curvilinear grid that is partitioned into chunks for parallelized simulation. A specific routine in MITgcm determines which observations belong to which chunk, and data must be formatted with knowledge of that routine. This is where `obsprep` comes in handy!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad6e3307-866e-4979-8ef6-9668ea7b13ad",
   "metadata": {},
   "source": [
    "### Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df7f6189-f789-48b8-8555-b56b667e5c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "\n",
    "import obsprep as op\n",
    "from obsprep.utils import generate_random_points\n",
    "\n",
    "np.random.seed(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42438906-ab17-4cbf-b58c-97319143a2f1",
   "metadata": {},
   "source": [
    "### Load grid dataset\n",
    "In this example, we have a premade dataset containing grid information from the $1^\\circ$ llc grid, the `llc90`. In order to generate this information for a user's model, we recommend [xmitgcm](https://xmitgcm.readthedocs.io/en/latest/usage.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18fbd9dc-d30b-43f0-9f61-6e648f90a2a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_ds = xr.open_dataset('../datasets/ECCO_llc90.nc')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c719957-1e36-4061-b423-5e8ee81826c3",
   "metadata": {},
   "source": [
    "### Generate random observation locations\n",
    "Here, the user may provide *ungridded* observational data. For simplicity, we generate random values of `lats`, `lons`, and `depths`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b268450c-2df4-4f2d-8afd-c701ea607a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "nobs = 10\n",
    "lons, lats, depths = generate_random_points(nobs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35359171-72a7-487f-acd4-a17913ea416e",
   "metadata": {},
   "source": [
    "### Initialize the `obsprep` object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9918648e-ba2d-4317-a55b-64f2dca49ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "OP = op.Prep('obsfit')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d995e7c7-05ad-43e3-b4e4-0e0201a7d664",
   "metadata": {},
   "source": [
    "### Get spatial interpolation information\n",
    "Here, we endow our synthetic dataset with interpolation information so that the model knows where to position our insitu data. The user relays knowledge of their parallel grid partitioning with the parameters `sNx` and `sNy` (see [here](https://mitgcm.readthedocs.io/en/latest/phys_pkgs/exch2.html#exch2-size-h-and-multiprocessing) for more details)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d8a2a7-0712-4f51-8614-f853d25df4df",
   "metadata": {},
   "outputs": [],
   "source": [
    "OP.get_obs_point(lons, lats, depths, grid_type='llc', grid_ds=grid_ds, num_interp_points=1, sNx=30, sNy=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e965f85-48d0-468e-ae0f-d47031439f6f",
   "metadata": {},
   "source": [
    "The observational dataset being generated is an `xarray.Dataset` object, which is itself an attribute of our `Prep` object, `OP.ds`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd1b50cf-784f-4095-8079-ceb026d734b5",
   "metadata": {},
   "source": [
    "### Generate temporal metadata\n",
    "Additionally, the `obsfit` package requires temporal fields to properly organize observations based on their occurrence during model simulation time. As with our observation locations, we generate random time fields, add them to the dataset under the name `obs_datetime`, and then obtain the temporal fields in a format the model expects, namely as fields `obs_YYYYMMDD`, `obs_HHMMSS`, and `obs_date`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8497a5a-333c-424c-9ad3-8005a5f428d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_datetime(nobs, start_date='1992-01-01', end_date='1993-01-01'):\n",
    "    # create datetime values \n",
    "    start_date = pd.to_datetime(start_date)\n",
    "    end_date = pd.to_datetime(end_date)\n",
    "    return np.random.choice(pd.date_range(start=start_date, end=end_date, freq='D'), size=nobs)\n",
    "\n",
    "obs_datetime = generate_datetime(nobs)\n",
    "OP.ds['obs_datetime'] = xr.DataArray(obs_datetime, dims=['iSAMPLE'])\n",
    "\n",
    "OP.get_obs_datetime(time_var = 'obs_datetime')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c440c53-eb48-4607-b223-60b958d36b50",
   "metadata": {},
   "source": [
    "### Set observational data and its `sample_type`\n",
    "Lastly, we create synthetic data in the dataset's `obs_val` field and indicate to the model the type of observations using integers according to the table below.\n",
    "\n",
    "| Field | Number | Name                    |\n",
    "|-------|--------|-------------------------|\n",
    "| T     | 1      | Temperature             |\n",
    "| S     | 2      | Salinity                |\n",
    "| U     | 3      | Zonal Velocity          |\n",
    "| V     | 4      | Meridional Velocity     |\n",
    "| SSH   | 5      | Sea Surface Height      |\n",
    "\n",
    "Note that creating dummy data in this way is not advised -- typically the user will format their actual observational data appropriately and insert it into the dataset now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "795d2ec8-7652-4539-ba40-9d9d84e6bc93",
   "metadata": {},
   "outputs": [],
   "source": [
    "theta_data = np.random.uniform(low=25, high=32, size=nobs)\n",
    "OP.ds['obs_val'] = xr.DataArray(theta_data, dims=['iSAMPLE'])\n",
    "\n",
    "# assign the integer value with knowledge that this is temperature data\n",
    "# this function populates the sample_type field\n",
    "OP.get_sample_type('T')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ba9f834-3798-4ec3-9f63-58ceeeba33ad",
   "metadata": {},
   "source": [
    "### Write out the dataset!\n",
    "Now our dataset has been created within the `OP` object, so we write it to netcdf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a050775b-4a40-49b4-9f33-1b3e96436629",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the dataset back from the preprocessing constructor\n",
    "ds = OP.ds.copy()\n",
    "ds.to_netcdf('../datasets/obsfit_llc_example.nc')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fd32106-f8e9-4809-888d-85b430afd8ec",
   "metadata": {},
   "source": [
    "# Extras\n",
    "Here are a couple more ways to explore the data used by the obsfit package.\n",
    "### 1. Plot\n",
    "We can plot where our random observations landed, as well as the depths we assigned them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f4cda97-71ed-41cd-9a33-db1cfa640cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cartopy.crs as ccrs\n",
    "plt.figure(figsize=(10, 4))\n",
    "ax = plt.axes(projection=ccrs.PlateCarree())\n",
    "sc = ax.scatter(ds['sample_lon'], ds['sample_lat'], c=ds['sample_depth'], cmap='viridis', s=100, edgecolor='k')\n",
    "ax.set_global()\n",
    "ax.coastlines()\n",
    "cbar = plt.colorbar(sc, orientation='vertical')\n",
    "cbar.set_label('Depth (m)')\n",
    "plt.title('Synthetic obsfit data', fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55806a7a-2999-4e2a-aee9-6b1008044000",
   "metadata": {},
   "source": [
    "### 2. Repeat tutorial beginning with an observational dataset\n",
    "It may be more straightforward to first assemble a dataset with ungridded observation points and data, then feed it into the `Prep` object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c45a943c-8d55-4d0e-93dc-2ec86e917c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_in = xr.Dataset(\n",
    "    {\n",
    "        'sample_lon': (('iSAMPLE',), lons),\n",
    "        'sample_lat': (('iSAMPLE',), lats),\n",
    "        'sample_depth': (('iSAMPLE',), depths),\n",
    "        'obs_datetime': (('iSAMPLE',), obs_datetime),\n",
    "        'obs_val': (('iSAMPLE',), theta_data)\n",
    "    },\n",
    ")\n",
    "\n",
    "OP = op.Prep('obsfit', ds_in)\n",
    "OP.get_obs_point(grid_type='llc', grid_ds=grid_ds, num_interp_points=1, sNx=30, sNy=30)\n",
    "OP.get_obs_datetime(time_var = 'obs_datetime')\n",
    "OP.get_sample_type('T')\n",
    "\n",
    "ds_out = OP.ds.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae084356-71bd-46b2-959c-b3eff6ef4cf8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
